version: '3.0'

expectations:
  population_size: 5000

actions:

  generate_study_population_ce1:
    run: cohortextractor:latest generate_cohort --study-definition study_definition_ce1_for_ce2 --index-date-range "2020-01-01 to 2020-12-01 by month"
    outputs:
      highly_sensitive:
        cohort: output/ce1/input_ce1_for_ce2_*.csv

  add_practice_ids:
    run: python:latest python analysis/add_practice_ids.py
    needs: [generate_study_population_ce1]
    outputs:
      moderately_sensitive:
        cohort: output/ce1/input_expanded_*.csv

  generate_study_population_ce2:
    run: cohortextractor-v2:latest generate_cohort --cohort-definition analysis/study_definition_ce2.py --output output/ce2/input_ce2_*.csv --dummy-data-file output/ce1/input_expanded_ce1_for_ce2_*.csv
    outputs:
      highly_sensitive:
        cohort: output/ce2/input_ce2_*.csv

  validate_cohort_v2:
    run: cohortextractor-v2:latest validate_cohort databricks --cohort-definition analysis/study_definition_ce2.py --output output/ce2/sql/generated_sql_*.sql
    outputs:
      moderately_sensitive:
        cohort: output/ce2/sql/generated_sql_*.sql

  # generate_measures:
  #   run: cohortextractor-v2:latest generate_measures --cohort-definition analysis/study_definition_ce2.py --output output/ce2/measure_ce2_*.csv --input=output/ce2/input_ce2_*.csv
  #   needs: [generate_study_population_ce2]
  #   outputs:
  #       moderately_sensitive:
  #         measure_csv: output/ce2/measure_ce2_*.csv


  # generate_report:
  #   run: cohort-report:v2.0.2 output/ce1/input_2019-09-01.feather
  #   needs: [generate_study_population_ce1]
  #   config:
  #     output_path: output/ce1/cohort_reports_outputs
  #   outputs:
  #     moderately_sensitive:
  #       reports: output/ce1/cohort_reports_outputs/*.html

    
  # generate_plots:
  #   run: python:latest python analysis/plot_measures.py
  #   needs: [generate_measures]
  #   outputs:
  #     moderately_sensitive:
  #       counts: output/ce2/figures/plot_*.jpeg